{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download, Inspect and Upload Permit Data\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import psycopg2\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call for bids:\n",
    "Call for bids are opened since 2017 every three months in different intervals (3-7 times a year). Bids must be submitted before the bid date. After the bid-date, the BNetzA publishes .xlsx tables listing the bid winners. The bid winners have a mastr_nummer (linking to the units)\n",
    "\n",
    "### Source-page: \n",
    "https://www.bundesnetzagentur.de/DE/Fachthemen/ElektrizitaetundGas/Ausschreibungen/Wind_Onshore/BeendeteAusschreibungen/start.html\n",
    "\n",
    "Stores links to the single pages, which hold the links to the .xlsx with the results (units) of the bids\n",
    "\n",
    "### Link leading to the bid-date pages:\n",
    "\n",
    "- Xpath-Expression (Selector-Gadget): `//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"NavNode\", \" \" ))]`\n",
    "- Xpath (Inspect-Browser-Plugin): `/html/body/div[1]/div/main/div/div[2]/div/div/div/table[1]/tbody/tr[1]/th[2]/p/a`\n",
    "- CSS-Selector (Selector-Gadget): `.NavNode`\n",
    "- CSS-Selector (Inspect-Browser-Plugin): `.bodyText > table:nth-child(6) > tbody:nth-child(3) > tr:nth-child(1) > th:nth-child(2) > p:nth-child(1) > a:nth-child(1)`\n",
    "- CSS-Path: `html body.gsb.js-off.main.ElektrizitaetUndGas div#wrapperOuter div#wrapperInner main#wrapperContentDivision.fwo.dapadding div.wrapperOuterContent div#wrapperContent.row div#content.col-lg-12.col-sm-12 div.wrapperText div.bodyText table tbody tr.odd th p.center a.RichTextIntLink.NavNode`\n",
    "\n",
    "- HTML-Tag: `<a class=\"RichTextIntLink NavNode\" href=\"DE/Fachthemen/ElektrizitaetundGas/Ausschreibungen/Wind_Onshore/BeendeteAusschreibungen/Ausschreibungen2023/Gebotstermin1022023/start.html\" title=\"Gebotstermin 1. Februar 2023\">Februar</a>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bids = \"https://www.bundesnetzagentur.de/DE/Fachthemen/ElektrizitaetundGas/Ausschreibungen/Wind_Onshore/BeendeteAusschreibungen/start.html\"\n",
    "\n",
    "### Response object holds all information sent by after making an http request to the url, \n",
    "# not only the html behind the visible page but also headers, status codes\n",
    "response_bids = requests.get(url_bids)\n",
    "\n",
    "### BeautifulSoup Object is a tree like structure for holding html\n",
    "soup_bids = BeautifulSoup(response_bids.content, 'html.parser')\n",
    "\n",
    "### Define what beautiful soup is supposed to look for\n",
    "# css-selector only and XPath-Expression did not work\n",
    "# Links are hardcoded into the site, so search for common html-tag:\n",
    "# Link starts with: <a class=\"RichTextIntLink NavNode\" - \n",
    "# <a> Tag with class-attribute RichText... and NavMode\n",
    "\n",
    "html_element = 'a'\n",
    "css_class = 'RichTextIntLink NavNode'\n",
    "\n",
    "# Find all <a> elements with the specified class attribute\n",
    "# Holds the whole html like '<a class=... href=... title=...>Displayed-Text</a>'\n",
    "links_html_bids = soup_bids.find_all(html_element, class_= css_class)\n",
    "\n",
    "# Extract the href attribute from each link\n",
    "urls_bid_date = [link['href'] for link in links_html_bids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### link to XLSX:\n",
    "\n",
    "- Xpath-Expression (Selector-Gadget): `//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"FTxlsx\", \" \" ))]`\n",
    "- Xpath (Inspect-Browser-Plugin): `/html/body/div[1]/div/main/div/div[2]/div/div[1]/div[1]/div[2]/a`\n",
    "\n",
    "- CSS-Selector (Selector-Gadget): `.FTxlsx`\n",
    "- CSS-Selector (Inspect-Browser-Plugin): `a.downloadLink:nth-child(4)`\n",
    "- CSS-Path: `html body.gsb.js-off.main.ElektrizitaetUndGas div#wrapperOuter div#wrapperInner main#wrapperContentDivision.fwo.dapadding div.wrapperOuterContent div#wrapperContent.row div#content.col-lg-12.col-sm-12 div.wrapperText div.bodyText div.MsoNormal.box2 a.downloadLink.Publication.FTxlsx`\n",
    "\n",
    "- HTML-Tag: `<a href=\"/SharedDocs/Downloads/DE/Sachgebiete/Energie/Unternehmen_Institutionen/Ausschreibungen/Onshore/Zuschlagslisten/ListeZuschlaege0112_2019.xlsx?__blob=publicationFile&amp;v=1\" class=\"downloadLink Publication FTxlsx\" title=\"zum&nbsp;Download:&nbsp;Liste der Zuschläge zum Gebotstermin 1. Dezember 2019&nbsp;(xlsx) (öffnet neues Fenster)\" target=\"_blank\">Liste der Zuschläge zum Gebotstermin 1. Dezember 2019&nbsp;<span>(xlsx / 26&nbsp;KB)  </span></a>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'DE/Fachthemen/ElektrizitaetundGas/Ausschreibungen/Wind_Onshore/BeendeteAusschreibungen/Ausschreibungen2023/Gebotstermin1022023/start.html\n",
    "# hrefs are internal/relative\n",
    "# When clicking the pointer from the source-page above the url looks like:\n",
    "# 'https://www.bundesnetzagentur.de/DE/Fachthemen/...'\n",
    "# So the stored hrefs must be headed by 'https://www.bundesnetzagentur.de/'\n",
    "source_url = 'https://www.bundesnetzagentur.de/'\n",
    "\n",
    "html_element = 'a'\n",
    "css_class = 'downloadLink Publication FTxlsx'\n",
    "\n",
    "css_selector = '.FTxlsx'\n",
    "xpath_expression = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"FTxlsx\", \" \" ))]'\n",
    "\n",
    "urls_xlsx = []\n",
    "### Open each link\n",
    "for href in urls_bid_date:\n",
    "    # add source_url\n",
    "    full_url = f\"{source_url}{href}\"\n",
    "    \n",
    "    # Find the .xlsx link\n",
    "    response_bid_date = requests.get(full_url)\n",
    "    \n",
    "    # extract the href\n",
    "    soup_bid_date = BeautifulSoup(response_bid_date.content, 'html.parser')\n",
    "    link_xslx_bid_date = soup_bid_date.select(css_selector)\n",
    "    \n",
    "    # Try Except for [0] out of range -> no .xlsx link\n",
    "    href_xlsx = link_xslx_bid_date[0]['href']\n",
    "    print(href_xlsx)\n",
    "    \n",
    "    # Download the .xlsx into ./data/mastr_bids\n",
    "    urls_xlsx.append(href_xlsx)\n",
    "    \n",
    "    # Pause to prevent security issues with the server\n",
    "    sleep_duration = random.randint(1,5)\n",
    "    time.sleep(sleep_duration)\n",
    "    # test wether the .blob url works for downloading\n",
    "    \n",
    "    # Do old and new links (change of link-syntax after)\n",
    "\n",
    "del sleep_duration, href, href_xlsx, full_url, soup_bid_date, link_xslx_bid_date, href_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded .xlsx for bid-date 2023-02-01\n",
      "Downloaded .xlsx for bid-date 2023-05-01\n",
      "Downloaded .xlsx for bid-date 2022-02-01\n",
      "Downloaded .xlsx for bid-date 2022-05-01\n",
      "Downloaded .xlsx for bid-date 2022-09-01\n",
      "Downloaded .xlsx for bid-date 2022-12-01\n",
      "Downloaded .xlsx for bid-date 2021-02-01\n",
      "Downloaded .xlsx for bid-date 2021-05-01\n",
      "Downloaded .xlsx for bid-date 2021-09-01\n",
      "Downloaded .xlsx for bid-date 2020-02-01\n",
      "Downloaded .xlsx for bid-date 2020-03-01\n",
      "Downloaded .xlsx for bid-date 2020-06-01\n",
      "Downloaded .xlsx for bid-date 2020-07-01\n",
      "Downloaded .xlsx for bid-date 2020-09-01\n",
      "Downloaded .xlsx for bid-date 2020-10-01\n",
      "Downloaded .xlsx for bid-date 2020-12-01\n",
      "Downloaded .xlsx for bid-date 2019-02-01\n",
      "Downloaded .xlsx for bid-date 2019-05-01\n",
      "Downloaded .xlsx for bid-date 2019-08-01\n",
      "Downloaded .xlsx for bid-date 2019-09-01\n",
      "Downloaded .xlsx for bid-date 2019-10-01\n",
      "Downloaded .xlsx for bid-date 2019-12-01\n",
      "Downloaded .xlsx for bid-date 2018-02-01\n",
      "Downloaded .xlsx for bid-date 2018-05-01\n",
      "Downloaded .xlsx for bid-date 2018-08-01\n",
      "Downloaded .xlsx for bid-date 2018-10-01\n"
     ]
    }
   ],
   "source": [
    "dict_xlsx = {}\n",
    "for xlsx in urls_xlsx:\n",
    "    # add source_url\n",
    "    full_url = f\"{source_url}{xlsx}\"\n",
    "    \n",
    "    # only name.xlsx?__blob=publicationFile&v=1' of the href \n",
    "    filename = xlsx.split(\"/\")[-1].rstrip(\"?__blob=publicationFile&v=1'\")\n",
    "    \n",
    "    # filenames in the same format\n",
    "    filename = filename.replace(\"_\", \"\")\n",
    "    \n",
    "    pattern = \"ListeZuschlaege\"\n",
    "    \n",
    "    filename = re.sub(pattern, lambda m: m.group() + \"_\", filename)\n",
    "    \n",
    "    # Pattern to look for a 7 digit date after the underscore\n",
    "    pattern = r\"_(\\d{7}.xlsx)$\"\n",
    "    # replacement insert 0 before the captured group (\\1)\n",
    "    replacement = r\"_0\\1\" \n",
    "    \n",
    "    filename = re.sub(pattern, replacement, filename)\n",
    "    \n",
    "    bid_date = filename.split(\"_\")[1].split(\".\")[0]\n",
    "    \n",
    "    # strptime - convert string holding date to datetime-object, .date() to store it without the time of the day\n",
    "    bid_date = datetime.strptime(bid_date, \"%d%m%Y\").date()\n",
    "    \n",
    "    response_xlsx = requests.get(full_url)\n",
    "    \n",
    "    full_path = f\"../data/mastr_bids/{filename}\"\n",
    "    \n",
    "    if response_xlsx.status_code == 200:\n",
    "        with open(file = full_path, mode = \"wb\") as xlsx_file:\n",
    "            xlsx_file.write(response_xlsx.content)\n",
    "        print(f\"Downloaded .xlsx for bid-date {bid_date}\")\n",
    "    else:\n",
    "        print(f\"Error: No Download .xlsx for bid-date {bid_date}\")\n",
    "    \n",
    "    dict_xlsx[bid_date] = full_path\n",
    "    \n",
    "    # Pause to prevent security issues with the server\n",
    "    sleep_duration = random.randint(1,5)\n",
    "    time.sleep(sleep_duration)\n",
    "\n",
    "# delete objects from within the loop\n",
    "del xlsx_file, full_path, full_url, response_xlsx, bid_date, filename, pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{datetime.date(2023, 2, 1): '../data/mastr_bids/ListeZuschlaege_01022023.xlsx',\n",
       " datetime.date(2023, 5, 1): '../data/mastr_bids/ListeZuschlaege_01052023.xlsx',\n",
       " datetime.date(2022, 2, 1): '../data/mastr_bids/ListeZuschlaege_01022022.xlsx',\n",
       " datetime.date(2022, 5, 1): '../data/mastr_bids/ListeZuschlaege_01052022.xlsx',\n",
       " datetime.date(2022, 9, 1): '../data/mastr_bids/ListeZuschlaege_01092022.xlsx',\n",
       " datetime.date(2022, 12, 1): '../data/mastr_bids/ListeZuschlaege_01122022.xlsx',\n",
       " datetime.date(2021, 2, 1): '../data/mastr_bids/ListeZuschlaege_01022021.xlsx',\n",
       " datetime.date(2021, 5, 1): '../data/mastr_bids/ListeZuschlaege_01052021.xlsx',\n",
       " datetime.date(2021, 9, 1): '../data/mastr_bids/ListeZuschlaege_01092021.xlsx',\n",
       " datetime.date(2020, 2, 1): '../data/mastr_bids/ListeZuschlaege_01022020.xlsx',\n",
       " datetime.date(2020, 3, 1): '../data/mastr_bids/ListeZuschlaege_01032020.xlsx',\n",
       " datetime.date(2020, 6, 1): '../data/mastr_bids/ListeZuschlaege_01062020.xlsx',\n",
       " datetime.date(2020, 7, 1): '../data/mastr_bids/ListeZuschlaege_01072020.xlsx',\n",
       " datetime.date(2020, 9, 1): '../data/mastr_bids/ListeZuschlaege_01092020.xlsx',\n",
       " datetime.date(2020, 10, 1): '../data/mastr_bids/ListeZuschlaege_01102020.xlsx',\n",
       " datetime.date(2020, 12, 1): '../data/mastr_bids/ListeZuschlaege_01122020.xlsx',\n",
       " datetime.date(2019, 2, 1): '../data/mastr_bids/ListeZuschlaege_01022019.xlsx',\n",
       " datetime.date(2019, 5, 1): '../data/mastr_bids/ListeZuschlaege_01052019.xlsx',\n",
       " datetime.date(2019, 8, 1): '../data/mastr_bids/ListeZuschlaege_01082019.xlsx',\n",
       " datetime.date(2019, 9, 1): '../data/mastr_bids/ListeZuschlaege_01092019.xlsx',\n",
       " datetime.date(2019, 10, 1): '../data/mastr_bids/ListeZuschlaege_01102019.xlsx',\n",
       " datetime.date(2019, 12, 1): '../data/mastr_bids/ListeZuschlaege_01122019.xlsx',\n",
       " datetime.date(2018, 2, 1): '../data/mastr_bids/ListeZuschlaege_01022018.xlsx',\n",
       " datetime.date(2018, 5, 1): '../data/mastr_bids/ListeZuschlaege_01052018.xlsx',\n",
       " datetime.date(2018, 8, 1): '../data/mastr_bids/ListeZuschlaege_01082018.xlsx',\n",
       " datetime.date(2018, 10, 1): '../data/mastr_bids/ListeZuschlaege_01102018.xlsx'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_xlsx\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
