{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download, Inspect and Upload Permit Data\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from pandas.api.types import is_datetime64_any_dtype\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import pickle of filenames of .xlsx with infos on bids\n",
    "with open(\"../data/mastr_bids/bids_xlsx.pkl\", mode = \"rb\") as pkl_file:\n",
    "    dict_xlsx = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. How does the header look like if we just raw-read the xlsx\n",
    "dict_dfs = {}\n",
    "for bid_date, path_xlsx in dict_xlsx.items():\n",
    "    key = bid_date.strftime(format=\"%Y-%m-%d\")\n",
    "    print(key)\n",
    "    \n",
    "    xlsx_file = openpyxl.load_workbook(path_xlsx)\n",
    "    \n",
    "    num_sheets = len(xlsx_file.sheetnames)\n",
    "    \n",
    "    if num_sheets > 1:   \n",
    "        sheet_to_read = 1\n",
    "    else:\n",
    "        sheet_to_read = 0\n",
    "         \n",
    "    raw_df = pd.read_excel(path_xlsx, sheet_name=sheet_to_read, header=None)\n",
    "    \n",
    "    # Which items of the first column equals the original first column name -> start of the DF\n",
    "    # inner statement returns a boolean series\n",
    "    # left outer statement half test_df[...] returns only these rows, where the value of the inner series is True\n",
    "    # with right statement .index.values[0] retrieve the index of the df and this just as a number (first occurence)\n",
    "    header_row = raw_df[raw_df[0].eq(\"Name des Bieters\")].index.values[0]\n",
    "    \n",
    "    dict_dfs[key] = pd.read_excel(path_xlsx, sheet_name=sheet_to_read, header=header_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inspect-Data\n",
    "for key, df in dict_dfs.items():\n",
    "    print(key)\n",
    "    print(df.columns)\n",
    "    print(\"\"\"\n",
    "          \n",
    "          =========================================\n",
    "          \n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data is still messy:\n",
    "\n",
    "#### merged rows in dfs in at least 2018. \n",
    "- the data does not have two sheets with compact and detailed data but only compact data\n",
    "- The feature \"Angegebner Standort der Anlage\" holds the values for BLD, Landkreis, PLZ, Gemeinde, Gemarkung, Flurstück and Mastr Nummer like: \n",
    "\n",
    "    BLD Niedersachsen, Landkreis Salzgitter, Stadt, PLZ 38239, Gemeinde Salzgitter, Gemarkung Barum:\n",
    "    Registernummer A4497640206941: Flur3: 1/1. \n",
    "    BLD Niedersachsen, Landkreis Salzgitter, Stadt, PLZ 38239, Gemeinde Salzgitter, Gemarkung Watenstedt:\n",
    "    Registernummer A9617510206917: Flur5: 1/22. Registernummer A3273890206938: Flur5: 1/23. Registernummer A5669430206922: Flur5: 2/10. \n",
    "\n",
    " Or:\n",
    "\n",
    "    Niedersachsen, Landkreis Stade, PLZ 21698, Gemeinde Brest, Gemarkung Brest:\n",
    "    Flur 2: 66/1; 66/2; 66/3 (SEE919421623876) \n",
    "    Flur 2: 71; 72 (SEE923510311766) \n",
    "    Gemarkung Wohlerst:\n",
    "    Flur 2: 157/5; 5/7; 1/6 (SEE964469396954) \n",
    "    Flur 2: 5/7 (SEE974053806455) \n",
    "    Flur 2: 7/5; 170/5 (SEE968430555418)\n",
    "\n",
    "- Here one Zuschlags-Nr encapsulates several power-units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count nr of columns:\n",
    "bid_date = []\n",
    "ncol = []\n",
    "for key, df in dict_dfs.items():\n",
    "    ncol.append(df.shape[1])\n",
    "    bid_date.append(key)\n",
    "\n",
    "pd.DataFrame({\"bid_date\":bid_date, \"ncol\":ncol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper function: When an item of 'Angegebener Standort der Anlage' is split into multiple groups\n",
    "### of Administrative Infos: Mastr nr, Flur/Flurst, the function extracts the infos from this item seperately:\n",
    "### dictionary of lists where the lists have the length of the nr of mastr_nrs in this split\n",
    "\n",
    "def extract_mastr_nr_location(split_units, split_administrative):\n",
    "    \n",
    "    # Unnecessary headers which are within the item\n",
    "    patterns_rem = [\"Landkreis\", r\"Stadt|kreisfreie Stadt\", \"Gemeinde\", \"PLZ\", \"Gemarkung\"]\n",
    "\n",
    "    # lists of infos to be filled\n",
    "    flur_list = []\n",
    "    mastr_nr = []\n",
    "    bld_list = []\n",
    "    landkreis_list = []\n",
    "    plz_list = []\n",
    "    gemeinde_list = []\n",
    "    gemarkung_list = []\n",
    "\n",
    "    # clear the info from unnecessary headers and further garbage\n",
    "    for pattern in patterns_rem:\n",
    "        split_administrative = re.sub(pattern, \"\", split_administrative)\n",
    "\n",
    "    names_administrative = [info.strip().rstrip(\"\\n\").rstrip(\":_x000D_\") for info in split_administrative.split(\", \")]\n",
    "    \n",
    "    if names_administrative[2] == \"\":\n",
    "        del names_administrative[2] \n",
    "\n",
    "    # loop: through the list with one item of \"Mastr: Flurst\" and append into the corresponding list\n",
    "    # split_administrative is not repetetive, but holds a different information in each item -> name of the administrative unit \n",
    "    # [\"name bundesland\", ... , \"name gemarkung\"]. So these Items are appended repetitively to the corresponding list\n",
    "\n",
    "    for unit in split_units:\n",
    "    # remove leading and trailing spaces and dots\n",
    "        unit = unit.strip(\" \").strip(\".\")\n",
    "        \n",
    "    # Split at first occurence of \": \"\n",
    "        unit_flurst = unit.split(\": \", maxsplit = 1)\n",
    "        flur_list.append(unit_flurst[1].replace(\". _x000D_\\n\", \"\")) #.rstrip(\"\\n\").rstrip(\":_x000D_\").rstrip(\".\"))\n",
    "        mastr_nr.append(unit_flurst[0])\n",
    "    \n",
    "        bld_list.append(names_administrative[0])\n",
    "        landkreis_list.append(names_administrative[1])\n",
    "        plz_list.append(names_administrative[2])\n",
    "        gemeinde_list.append(names_administrative[3])\n",
    "        gemarkung_list.append(names_administrative[4])\n",
    "\n",
    "    dict_row = {'Bundesland':bld_list,\n",
    "       'Landkreis':landkreis_list, \n",
    "       'Postleitzahl':plz_list, \n",
    "       'Gemeinde':gemeinde_list, \n",
    "       'Gemarkung':gemarkung_list,\n",
    "       'Register_Anlagennr':mastr_nr,\n",
    "       'Flur / Flurstück':flur_list}\n",
    "\n",
    "    return dict_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### final function to apply onto the items of \"Angegebener Standort der Anlage\"\n",
    "def extract_info_standort(item_standort, item_zuschlags_nr):\n",
    "    \n",
    "    # First split: Seperate the possibly multiple BLD ... Gemarkung: Regnr Flur: Flurstück into several of these, \n",
    "    # each starting with BLD ... Gemarkung. So that all witihn one item of the first split level are in the same \n",
    "    # administrative borders (bundesland -> gemarkung is the same)\n",
    "    # Each of the these splits can hold multiple units (mastr_nr) with the corresponding Flur/Flurst entry\n",
    "    split_list_top = item_standort.split(\"BLD\")[1:]\n",
    "    \n",
    "    # Extract a dictionary of lists with repetitive administrative names and\n",
    "    # unique units (mastr_nr) and the flur/flurst these are within\n",
    "    # Make a df of these dicts\n",
    "    \n",
    "    # Create empty df first\n",
    "    df_result = pd.DataFrame()\n",
    "    \n",
    "    for split_top in split_list_top:\n",
    "        \n",
    "        # Second split. [0] item administrative info BLD -> Gemarkung\n",
    "        #               [1:] item Regnr Flur/Flurstück  \n",
    "        split_list_admin = split_top.split(\"Registernummer\")\n",
    "\n",
    "        # Lokational info BLD -> Gemarkung\n",
    "        split_administrative = split_list_admin[0]\n",
    "\n",
    "        # [1:] item Regnr Flur/Flurstück\n",
    "        split_units = split_list_admin[1:]\n",
    "        \n",
    "        dict_row = extract_mastr_nr_location(split_units=split_units, \n",
    "                                             split_administrative=split_administrative)\n",
    "        \n",
    "        if df_result.empty:\n",
    "            \n",
    "            df_result = pd.DataFrame(dict_row)\n",
    "            \n",
    "        else:\n",
    "            df_result = pd.concat([df_result, \n",
    "                                   pd.DataFrame(dict_row)], ignore_index=True)       \n",
    "    \n",
    "    df_result[\"Zuschlags-Nr\"] = [item_zuschlags_nr] * len(df_result)\n",
    "    \n",
    "    return df_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Problem only present for two dates: \n",
    "# 2018-02-01\t5 columns\n",
    "# 2018-05-01    4 columns\n",
    "\n",
    "test_df = dict_dfs[\"2018-02-01\"]\n",
    "\n",
    "test_item = test_df[\"Angegebener Standort der Anlage\"][0]\n",
    "\n",
    "test_zuschlags_nr = test_df[\"Zuschlags-Nr\"][0]\n",
    "\n",
    "# BLD Niedersachsen, Landkreis Salzgitter, Stadt, PLZ 38239, Gemeinde Salzgitter, Gemarkung Barum:\n",
    "# Registernummer A4497640206941: Flur3: 1/1. \n",
    "# BLD Niedersachsen, Landkreis Salzgitter, Stadt, PLZ 38239, Gemeinde Salzgitter, Gemarkung Watenstedt:\n",
    "# Registernummer A9617510206917: Flur5: 1/22. Registernummer A3273890206938: Flur5: 1/23. Registernummer A5669430206922: Flur5: 2/10.\n",
    "\n",
    "# Can the string be divided by BLD?\n",
    "# If at least the Gemarkung changes (lowest administrational level above flurstück)\n",
    "# the whole sequence of Bundesland\tLandkreis\tPostleitzahl\tGemeinde\tGemarkung\n",
    "# seems to repeat\n",
    "\n",
    "extract_info_standort(test_item, test_zuschlags_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy_column = \"Angegebener Standort der Anlage\"\n",
    "bid_nr = \"Zuschlags-Nr\"\n",
    "bid_date = \"2018-02-01\"\n",
    "\n",
    "dict_cleaned_dfs = {}\n",
    "df_2018_02_01 = dict_dfs[bid_date]\n",
    "\n",
    "# Empty long df to be filled and merged with the remainder of the messy-df\n",
    "df_2018_long = pd.DataFrame()\n",
    "\n",
    "for index, row in df_2018_02_01.iterrows():\n",
    "    \n",
    "    df_bid_nr = extract_info_standort(row[messy_column], row[bid_nr])\n",
    "    \n",
    "    if df_2018_long.empty:\n",
    "        df_2018_long = df_bid_nr\n",
    "    else:\n",
    "        df_2018_long = pd.concat([df_2018_long, df_bid_nr], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visually inspected and compared with downloaded .xlsx -> seems fine\n",
    "df_2018_long\n",
    "\n",
    "### Merge with the columns not presend in [df_2018_long\n",
    "cols_keep = [col for col in df_2018_02_01.columns if col not in df_2018_long.columns]\n",
    "cols_keep.append(bid_nr)\n",
    "\n",
    "dict_cleaned_dfs[bid_date] = pd.merge(df_2018_02_01[cols_keep], df_2018_long, on=bid_nr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
